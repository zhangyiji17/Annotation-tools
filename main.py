import gradio as gr
import os
import json
import time
import tempfile
from pathlib import Path
from typing import List, Dict, Generator, Tuple, Any, Optional
import pandas as pd
import cv2
import numpy as np
from PIL import Image, ImageDraw
import base64
import io
import shutil
import uuid

from config import Config, PRESETS, API_CONFIG
from api_handler import APIHandler
from pdf_processor import PDFProcessor
from yolo_detector import YOLODetector

# åˆ›å»ºç›®å½•
Config.create_dirs()

# åˆå§‹åŒ–YOLOæ£€æµ‹å™¨ï¼ˆæ‡’åŠ è½½ï¼‰
yolo_detector = None
current_yolo_model_path = None
current_task_subtype = "ç›®æ ‡æ£€æµ‹"

# å…¨å±€å˜é‡å­˜å‚¨å½“å‰å¤„ç†ç»“æœ
current_results = []
current_task_type = ""
current_file_paths = []
current_visualizations = []
current_detections = {}
current_original_images = {}
current_editing_mode = False
current_edit_image_index = -1
current_edit_annotations = []


def get_yolo_detector(model_path=None, task_subtype="ç›®æ ‡æ£€æµ‹"):
    """è·å–æˆ–åˆå§‹åŒ–YOLOæ£€æµ‹å™¨"""
    global yolo_detector, current_yolo_model_path, current_task_subtype

    # æ¸…ç†ä»»åŠ¡ç±»å‹å­—ç¬¦ä¸²
    if isinstance(task_subtype, str):
        task_subtype = clean_task_subtype(task_subtype)

    # ç¡®å®šæ¨¡å‹è·¯å¾„
    if model_path is not None:
        final_model_path = model_path
    elif current_yolo_model_path is not None:
        final_model_path = current_yolo_model_path
    else:
        final_model_path = Config.YOLO_MODEL_PATH

    print(f"ğŸ”„ åˆå§‹åŒ–YOLOæ£€æµ‹å™¨: æ¨¡å‹={final_model_path}, ä»»åŠ¡ç±»å‹={task_subtype}")

    try:
        yolo_detector = YOLODetector(model_path=final_model_path, task_subtype=task_subtype)
        current_yolo_model_path = final_model_path
        current_task_subtype = task_subtype
        return yolo_detector
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–YOLOæ£€æµ‹å™¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def clean_task_subtype(task_subtype: str) -> str:
    """æ¸…ç†ä»»åŠ¡ç±»å‹å­—ç¬¦ä¸²ï¼Œç§»é™¤è¡¨æƒ…ç¬¦å·"""
    if not isinstance(task_subtype, str):
        return "ç›®æ ‡æ£€æµ‹"

    # ç§»é™¤å¸¸è§çš„è¡¨æƒ…ç¬¦å·
    emoji_map = {
        "ğŸ¯ ": "",
        "ğŸ–¼ï¸ ": "",
        "ğŸ–Œï¸ ": "",
        "ğŸ¯": "",
        "ğŸ–¼ï¸": "",
        "ğŸ–Œï¸": ""
    }

    for emoji, replacement in emoji_map.items():
        task_subtype = task_subtype.replace(emoji, replacement)

    # ç¡®ä¿æ˜¯æœ‰æ•ˆçš„ä»»åŠ¡ç±»å‹
    valid_types = ["ç›®æ ‡æ£€æµ‹", "å›¾åƒåˆ†ç±»", "å®ä¾‹åˆ†å‰²"]
    if task_subtype.strip() in valid_types:
        return task_subtype.strip()
    else:
        return "ç›®æ ‡æ£€æµ‹"


def test_api_connection(api_key: str, model_type: str):
    """æµ‹è¯•APIè¿æ¥"""
    if not api_key.strip():
        return "âŒ è¯·è¾“å…¥APIå¯†é’¥"

    try:
        handler = APIHandler(model_type, api_key.strip())
        if handler.test_connection():
            return f"âœ… {model_type} è¿æ¥æˆåŠŸ"
        else:
            return f"âŒ {model_type} è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥"
    except Exception as e:
        return f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"


def update_text_input_group(task_type_value):
    """æ ¹æ®ä»»åŠ¡ç±»å‹æ›´æ–°æ–‡æœ¬è¾“å…¥ç»„çš„æ˜¾ç¤º"""
    if task_type_value == "é—®ç­”å¯¹ç”Ÿæˆ":
        return gr.update(visible=True)
    else:
        return gr.update(visible=False)


def update_file_upload(task_type_value):
    """æ ¹æ®ä»»åŠ¡ç±»å‹æ›´æ–°æ–‡ä»¶ä¸Šä¼ ç»„ä»¶"""
    if task_type_value == "é—®ç­”å¯¹ç”Ÿæˆ":
        return gr.update(file_types=[".pdf"], visible=True)
    elif task_type_value == "å›¾åƒä»»åŠ¡":
        return gr.update(file_types=[".jpg", ".jpeg", ".png", ".bmp", ".gif", ".tiff", ".webp"], visible=True)
    else:  # å¤šæ¨¡æ€ç”Ÿæˆ
        return gr.update(file_types=[".jpg", ".jpeg", ".png", ".bmp", ".gif"], visible=True)


def update_ui_components(task_type_value):
    """æ ¹æ®ä»»åŠ¡ç±»å‹æ›´æ–°æ‰€æœ‰UIç»„ä»¶"""
    updates = []

    if task_type_value == "é—®ç­”å¯¹ç”Ÿæˆ":
        updates = [
            gr.update(visible=True),  # model_type
            gr.update(visible=True),  # api_key
            gr.update(visible=True),  # test_btn
            gr.update(visible=True),  # test_output
            gr.update(visible=False),  # yolo_config_group
            gr.update(visible=True),  # preset_type
            gr.update(visible=True),  # concurrency
            gr.update(visible=False),  # visualization_group
            gr.update(visible=False),  # image_navigation_group
            gr.update(value="é—®ç­”å¯¹ç”Ÿæˆ"),  # æ›´æ–°ä»»åŠ¡ç±»å‹çŠ¶æ€
            gr.update(visible=False),  # éšè—vision_model
            gr.update(visible=True),  # æ˜¾ç¤ºè‡ªå®šä¹‰æç¤ºè¯ç»„
            gr.update(visible=True),  # æ˜¾ç¤ºæ–‡æœ¬è¾“å…¥ç»„
            gr.update(visible=False),  # éšè—ç¼–è¾‘æŒ‰é’®
            gr.update(visible=False)  # éšè—ç¼–è¾‘æ§åˆ¶ç»„
        ]
    elif task_type_value == "å›¾åƒä»»åŠ¡":
        updates = [
            gr.update(visible=False),  # model_type
            gr.update(visible=False),  # api_key
            gr.update(visible=False),  # test_btn
            gr.update(visible=False),  # test_output
            gr.update(visible=True),  # yolo_config_group
            gr.update(visible=False),  # preset_type
            gr.update(visible=False),  # concurrency
            gr.update(visible=True),  # visualization_group
            gr.update(visible=True),  # image_navigation_group
            gr.update(value="å›¾åƒä»»åŠ¡"),  # æ›´æ–°ä»»åŠ¡ç±»å‹çŠ¶æ€
            gr.update(visible=False),  # éšè—vision_model
            gr.update(visible=False),  # éšè—è‡ªå®šä¹‰æç¤ºè¯ç»„
            gr.update(visible=False),  # éšè—æ–‡æœ¬è¾“å…¥ç»„
            gr.update(visible=True),  # æ˜¾ç¤ºç¼–è¾‘æŒ‰é’®
            gr.update(visible=False)  # éšè—ç¼–è¾‘æ§åˆ¶ç»„ï¼ˆåˆå§‹çŠ¶æ€ï¼‰
        ]
    else:  # å¤šæ¨¡æ€ç”Ÿæˆ
        updates = [
            gr.update(visible=True),  # model_type
            gr.update(visible=True),  # api_key
            gr.update(visible=True),  # test_btn
            gr.update(visible=True),  # test_output
            gr.update(visible=False),  # yolo_config_group
            gr.update(visible=False),  # preset_type
            gr.update(visible=True),  # concurrency
            gr.update(visible=False),  # visualization_group
            gr.update(visible=False),  # image_navigation_group
            gr.update(value="å¤šæ¨¡æ€ç”Ÿæˆ"),  # æ›´æ–°ä»»åŠ¡ç±»å‹çŠ¶æ€
            gr.update(visible=True),  # æ˜¾ç¤ºvision_model
            gr.update(visible=False),  # éšè—è‡ªå®šä¹‰æç¤ºè¯ç»„
            gr.update(visible=False),  # éšè—æ–‡æœ¬è¾“å…¥ç»„
            gr.update(visible=False),  # éšè—ç¼–è¾‘æŒ‰é’®
            gr.update(visible=False)  # éšè—ç¼–è¾‘æ§åˆ¶ç»„
        ]

    return updates


def handle_local_model_upload(file):
    """å¤„ç†æœ¬åœ°æ¨¡å‹ä¸Šä¼ """
    global current_yolo_model_path

    if file is None:
        return (
            gr.update(value=None),  # æ¸…é™¤æ–‡ä»¶è¾“å…¥
            gr.update(value="è¯·ä¸Šä¼ æœ¬åœ°.ptæ¨¡å‹æ–‡ä»¶"),  # æ¨¡å‹çŠ¶æ€
            gr.update(value="æœ¬åœ°æ¨¡å‹")  # æ›´æ–°æ¨¡å‹é€‰æ‹©æŒ‰é’®
        )

    try:
        # è·å–ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
        if hasattr(file, 'name'):
            model_path = file.name
        else:
            model_path = str(file)

        print(f"ğŸ“ ä¸Šä¼ æ¨¡å‹æ–‡ä»¶: {model_path}")

        # éªŒè¯æ–‡ä»¶æ‰©å±•å
        if not model_path.lower().endswith('.pt'):
            return (
                gr.update(value=None),
                gr.update(value="âŒ è¯·é€‰æ‹©.ptæ ¼å¼çš„æ¨¡å‹æ–‡ä»¶"),
                gr.update(value="yolo11n.pt")  # æ¢å¤åˆ°é»˜è®¤æ¨¡å‹
            )

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            return (
                gr.update(value=None),
                gr.update(value=f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}"),
                gr.update(value="yolo11n.pt")
            )

        # è·å–æ–‡ä»¶ä¿¡æ¯
        filename = os.path.basename(model_path)
        file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB

        # å¦‚æœæ˜¯yolov5æ¨¡å‹ï¼Œè­¦å‘Šç”¨æˆ·å¯èƒ½å­˜åœ¨é—®é¢˜
        warning_msg = ""
        if 'yolov5' in filename.lower():
            warning_msg = f"âš ï¸ æ³¨æ„ï¼šYOLOv5æ¨¡å‹åœ¨åŠ è½½æ—¶å¯èƒ½ä¼šå°è¯•åŠ è½½å¸¦'u'åç¼€çš„ç‰ˆæœ¬ï¼Œå¦‚æœå¤±è´¥è¯·å°è¯•ä½¿ç”¨YOLOv8æˆ–YOLOv11æ¨¡å‹"

        # æ£€æŸ¥modelsç›®å½•æ˜¯å¦å·²å­˜åœ¨åŒåæ–‡ä»¶
        saved_model_path = os.path.join(Config.MODEL_DIR, filename)

        if os.path.exists(saved_model_path):
            print(f"ğŸ”„ å‘ç°åŒåæ¨¡å‹æ–‡ä»¶ï¼Œå°†è¦†ç›–æ›¿æ¢: {saved_model_path}")
            # # å¤‡ä»½åŸæœ‰æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            # backup_path = f"{saved_model_path}.backup_{int(time.time())}"
            # try:
            #     shutil.copy2(saved_model_path, backup_path)
            #     print(f"ğŸ“¦ å·²å¤‡ä»½åŸæ–‡ä»¶åˆ°: {backup_path}")
            # except Exception as backup_error:
            #     print(f"âš ï¸  å¤‡ä»½åŸæ–‡ä»¶å¤±è´¥: {backup_error}")

            # è¦†ç›–æ›¿æ¢
            shutil.copy2(model_path, saved_model_path)
            print(f"âœ… æ¨¡å‹å·²è¦†ç›–: {saved_model_path}")
        else:
            # ç›´æ¥å¤åˆ¶æ–°æ–‡ä»¶
            shutil.copy2(model_path, saved_model_path)
            print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {saved_model_path}")

        # æ›´æ–°å…¨å±€å˜é‡
        current_yolo_model_path = saved_model_path

        status_msg = f"âœ… å·²é€‰æ‹©æœ¬åœ°æ¨¡å‹: {filename} ({file_size:.1f}MB)"
        print(status_msg)

        if warning_msg:
            status_msg += f"\n{warning_msg}"

        return (
            gr.update(value=None),  # æ¸…é™¤æ–‡ä»¶è¾“å…¥
            gr.update(value=status_msg),  # æ›´æ–°æ¨¡å‹çŠ¶æ€
            gr.update(value="æœ¬åœ°æ¨¡å‹")  # ç¡®ä¿æ¨¡å‹é€‰æ‹©æŒ‰é’®è¢«é€‰ä¸­
        )
    except Exception as e:
        print(f"âŒ å¤„ç†æ¨¡å‹æ–‡ä»¶å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return (
            gr.update(value=None),
            gr.update(value=f"âŒ å¤„ç†æ¨¡å‹æ–‡ä»¶å¤±è´¥: {str(e)}"),
            gr.update(value="yolo11n.pt")
        )


def update_yolo_model_selection(yolo_model_select_value):
    """æ›´æ–°YOLOæ¨¡å‹é€‰æ‹©å’Œæ˜¾ç¤º"""
    global current_yolo_model_path

    print(f"ğŸ”„ æ›´æ–°æ¨¡å‹é€‰æ‹©: {yolo_model_select_value}")

    # å¤„ç†ä¸åŒçš„æ¨¡å‹é€‰æ‹©
    if yolo_model_select_value == "yolo11n.pt":
        model_path = Config.YOLO_MODEL_PATH
        current_yolo_model_path = model_path
        if os.path.exists(model_path):
            model_info = f"**é»˜è®¤æ¨¡å‹:** yolo11n.pt"
        else:
            model_info = "âŒ **é»˜è®¤æ¨¡å‹ yolo11n.pt ä¸å­˜åœ¨ï¼Œè¯·å°†æ¨¡å‹æ–‡ä»¶æ”¾ç½®åœ¨ models/ ç›®å½•ä¸‹**"
        return (
            gr.update(visible=True),  # yolo_model_select ä¿æŒå¯è§
            gr.update(visible=False),  # éšè—æœ¬åœ°æ¨¡å‹ä¸Šä¼ ç»„ä»¶
            gr.update(value=model_info)  # æ›´æ–°æ¨¡å‹ä¿¡æ¯
        )
    elif yolo_model_select_value == "æœ¬åœ°æ¨¡å‹":
        # æ˜¾ç¤ºæœ¬åœ°æ¨¡å‹ä¸Šä¼ ç»„ä»¶
        # æ£€æŸ¥æ˜¯å¦æœ‰å·²ç»ä¸Šä¼ çš„æœ¬åœ°æ¨¡å‹
        if current_yolo_model_path and os.path.exists(current_yolo_model_path):
            filename = os.path.basename(current_yolo_model_path)
            model_info = f"**å½“å‰æ¨¡å‹:** {filename}"
        else:
            model_info = "**è¯·ä¸Šä¼ æœ¬åœ°.ptæ¨¡å‹æ–‡ä»¶**"

        return (
            gr.update(visible=True),  # yolo_model_select ä¿æŒå¯è§
            gr.update(visible=True),  # æ˜¾ç¤ºæœ¬åœ°æ¨¡å‹ä¸Šä¼ ç»„ä»¶
            gr.update(value=model_info)  # æ›´æ–°æ¨¡å‹ä¿¡æ¯
        )
    else:
        # å¦‚æœä¼ å…¥äº†å…¶ä»–å€¼ï¼Œä¿æŒå½“å‰çŠ¶æ€
        return (
            gr.update(visible=True),
            gr.update(visible=False),
            gr.update(
                value=f"**æ¨¡å‹:** {os.path.basename(yolo_model_select_value) if isinstance(yolo_model_select_value, str) else 'æœªçŸ¥'}")
        )


def update_image_task_ui(task_subtype, yolo_model_select):
    """æ›´æ–°å›¾åƒä»»åŠ¡UIç»„ä»¶"""
    global current_yolo_model_path

    # æ¸…ç†ä»»åŠ¡ç±»å‹ï¼ˆç§»é™¤è¡¨æƒ…ç¬¦å·ï¼‰
    cleaned_subtype = clean_task_subtype(task_subtype)

    # æ›´æ–°æ¨¡å‹é€‰æ‹©ç»„ä»¶çš„å¯è§æ€§
    if cleaned_subtype in ["ç›®æ ‡æ£€æµ‹", "å›¾åƒåˆ†ç±»", "å®ä¾‹åˆ†å‰²"]:
        yolo_select_visible = True
        # åªæœ‰å½“é€‰æ‹©äº†"æœ¬åœ°æ¨¡å‹"æ—¶æ‰æ˜¾ç¤ºä¸Šä¼ ç»„ä»¶
        local_upload_visible = (yolo_model_select == "æœ¬åœ°æ¨¡å‹")
    else:
        yolo_select_visible = False
        local_upload_visible = False

    # æ›´æ–°æ¨¡å‹ä¿¡æ¯æ˜¾ç¤º
    if yolo_model_select == "yolo11n.pt":
        model_info_text = f"**ä»»åŠ¡:** {cleaned_subtype} | **æ¨¡å‹:** yolo11n.pt"
        model_status_text = "é»˜è®¤æ¨¡å‹"
    elif yolo_model_select == "æœ¬åœ°æ¨¡å‹" and current_yolo_model_path and os.path.exists(current_yolo_model_path):
        filename = os.path.basename(current_yolo_model_path)
        model_info_text = f"**ä»»åŠ¡:** {cleaned_subtype} | **æ¨¡å‹:** {filename}"
        model_status_text = "æœ¬åœ°æ¨¡å‹æˆåŠŸåŠ è½½"
    else:
        model_info_text = f"**ä»»åŠ¡:** {cleaned_subtype} | **æ¨¡å‹:** æœªé€‰æ‹©"
        model_status_text = "æœªé€‰æ‹©"

    return (
        gr.update(visible=yolo_select_visible),  # yolo_model_select
        gr.update(visible=local_upload_visible),  # local_model_upload_group
        gr.update(value=model_info_text),  # model_info
        gr.update(value=model_status_text)  # model_status_text
    )


def collect_files(files):
    """æ”¶é›†æ‰€æœ‰æ–‡ä»¶ï¼Œæ”¯æŒæ–‡ä»¶å’Œæ–‡ä»¶å¤¹"""
    all_files = []

    if not files:
        return []

    for file_info in files:
        file_path = file_info.name

        # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œéå†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        if os.path.isdir(file_path):
            image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp']
            for root, dirs, walk_files in os.walk(file_path):
                for file in walk_files:
                    if any(file.lower().endswith(ext) for ext in image_extensions):
                        all_files.append({
                            'name': os.path.join(root, file),
                            'is_file': True
                        })
        # å¦‚æœæ˜¯æ–‡ä»¶
        else:
            all_files.append({
                'name': file_path,
                'is_file': True
            })

    return all_files


def process_files(files, task_type, model_type, api_key, preset_type,
                  custom_system_prompt, custom_task_prompt, concurrency,
                  text_input=None, vision_model="",
                  task_subtype="ğŸ¯ ç›®æ ‡æ£€æµ‹", yolo_model_select="yolo11n.pt",
                  local_model_file=None, conf_threshold=0.25):
    """å¤„ç†æ–‡ä»¶çš„ä¸»å‡½æ•° - è¿”å›ç”Ÿæˆå™¨"""

    global current_results, current_task_type, current_file_paths, current_visualizations, current_detections, current_original_images, current_editing_mode, current_edit_image_index, current_edit_annotations, current_task_subtype, current_yolo_model_path

    # é‡ç½®å…¨å±€å˜é‡
    current_results = []
    current_file_paths = []
    current_visualizations = []
    current_detections = {}
    current_original_images = {}
    current_editing_mode = False
    current_edit_image_index = -1
    current_edit_annotations = []
    current_task_type = task_type

    # æ¸…ç†ä»»åŠ¡ç±»å‹å­—ç¬¦ä¸²
    cleaned_task_subtype = clean_task_subtype(task_subtype)
    current_task_subtype = cleaned_task_subtype if task_type == "å›¾åƒä»»åŠ¡" else ""

    # å¤„ç†æ–‡æœ¬è¾“å…¥çš„æƒ…å†µ
    if task_type == "é—®ç­”å¯¹ç”Ÿæˆ" and text_input and text_input.strip():
        # ä¼˜å…ˆå¤„ç†æ–‡æœ¬è¾“å…¥
        if not api_key.strip():
            yield "è¯·è¾“å…¥APIå¯†é’¥", None, None, None, None, gr.update(visible=False)
            return

        handler = APIHandler(model_type, api_key.strip())
        results = []

        # è·å–æç¤ºè¯
        if preset_type == "è‡ªå®šä¹‰æç¤ºè¯":
            system_prompt = custom_system_prompt or "ä½ æ˜¯ä¸€ä¸ªå·¥ä¸šçŸ¥è¯†ä¸“å®¶"
        else:
            preset = PRESETS.get(preset_type, {})
            system_prompt = preset.get("system_prompt", "ä½ æ˜¯ä¸€ä¸ªå·¥ä¸šçŸ¥è¯†ä¸“å®¶")

        # å¤„ç†æ–‡æœ¬è¾“å…¥
        chunks = [{"text": text_input, "source_file": "æ–‡æœ¬è¾“å…¥", "page": 1}]

        for j, chunk in enumerate(chunks):
            qa_pairs = handler.generate_qa(chunk["text"], system_prompt)

            for qa in qa_pairs:
                result = {
                    "id": f"{len(results) + 1:04d}",
                    "task_type": preset_type,
                    "system_prompt": system_prompt,
                    "instruction": qa.get("instruction", ""),
                    "output": qa.get("output", ""),
                    "source_file": "æ–‡æœ¬è¾“å…¥",
                    "page_num": 1
                }
                results.append(result)

            yield f"æ­£åœ¨å¤„ç†æ–‡æœ¬æ®µè½ {j + 1}/{len(chunks)}ï¼Œå·²ç”Ÿæˆ {len(results)} æ¡æ•°æ®", None, None, None, None, gr.update(
                visible=False)

        # ä¿å­˜ç»“æœ
        if results:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_path = os.path.join(Config.OUTPUT_DIR, f"text_qa_results_{timestamp}.json")

            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)

            final_msg = f"âœ… å®Œæˆï¼å·²ç”Ÿæˆ {len(results)} æ¡QAæ•°æ®\nå·²ä¿å­˜åˆ°: {output_path}"
            df_results = pd.DataFrame(results)
            current_results = results
            yield final_msg, df_results, None, None, None, gr.update(visible=True)
        else:
            yield "âŒ æœªèƒ½ç”Ÿæˆä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡æœ¬å†…å®¹æˆ–APIé…ç½®", None, None, None, None, gr.update(visible=False)

        return

    # æ”¶é›†æ‰€æœ‰æ–‡ä»¶
    all_file_infos = collect_files(files)

    if not all_file_infos:
        yield "è¯·å…ˆä¸Šä¼ æ–‡ä»¶æˆ–è¾“å…¥æ–‡æœ¬", None, None, None, None, gr.update(visible=False)
        return

    results = []
    visualizations = []
    file_paths = []
    current_image_index = 0

    try:
        if task_type == "é—®ç­”å¯¹ç”Ÿæˆ":
            # ... [åŸæœ‰çš„é—®ç­”å¯¹ç”Ÿæˆä»£ç ä¿æŒä¸å˜] ...
            if not api_key.strip():
                yield "è¯·è¾“å…¥APIå¯†é’¥", None, None, None, None, gr.update(visible=False)
                return

            handler = APIHandler(model_type, api_key.strip())
            total_files = len(all_file_infos)

            for i, file_info in enumerate(all_file_infos):
                file_path = file_info['name']
                filename = os.path.basename(file_path)
                file_paths.append(file_path)
                status_msg = f"æ­£åœ¨å¤„ç†æ–‡ä»¶ {i + 1}/{total_files}: {filename}"
                yield status_msg, None, None, None, None, gr.update(visible=False)

                chunks = PDFProcessor.extract_text(file_path)

                if preset_type == "è‡ªå®šä¹‰æç¤ºè¯":
                    system_prompt = custom_system_prompt or "ä½ æ˜¯ä¸€ä¸ªå·¥ä¸šçŸ¥è¯†ä¸“å®¶"
                else:
                    preset = PRESETS.get(preset_type, {})
                    system_prompt = preset.get("system_prompt", "ä½ æ˜¯ä¸€ä¸ªå·¥ä¸šçŸ¥è¯†ä¸“å®¶")

                total_chunks = len(chunks)
                for j, chunk in enumerate(chunks):
                    progress_msg = f"{status_msg}\næ­£åœ¨å¤„ç†æ®µè½ {j + 1}/{total_chunks}..."
                    yield progress_msg, None, None, None, None, gr.update(visible=False)

                    qa_pairs = handler.generate_qa(chunk["text"], system_prompt)

                    for qa in qa_pairs:
                        result = {
                            "id": f"{len(results) + 1:04d}",
                            "task_type": preset_type,
                            "system_prompt": system_prompt,
                            "instruction": qa.get("instruction", ""),
                            "output": qa.get("output", ""),
                            "source_file": chunk["source_file"],
                            "page_num": chunk["page"]
                        }
                        results.append(result)

                    time.sleep(0.1)

                yield f"å·²å®Œæˆæ–‡ä»¶ {filename}ï¼Œå·²ç”Ÿæˆ {len(results)} æ¡æ•°æ®", None, None, None, None, gr.update(
                    visible=False)

            if results:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                output_path = os.path.join(Config.OUTPUT_DIR, f"qa_results_{timestamp}.json")

                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)

                final_msg = f"âœ… å®Œæˆï¼å·²ç”Ÿæˆ {len(results)} æ¡QAæ•°æ®\nå·²ä¿å­˜åˆ°: {output_path}"
                df_results = pd.DataFrame(results)
                current_results = results
                current_file_paths = file_paths
                yield final_msg, df_results, None, None, None, gr.update(visible=True)
            else:
                yield "âŒ æœªèƒ½ç”Ÿæˆä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹æˆ–APIé…ç½®", None, None, None, None, gr.update(visible=False)

        elif task_type == "å›¾åƒä»»åŠ¡":
            # ç¡®å®šæ¨¡å‹è·¯å¾„
            model_path = None

            if yolo_model_select == "yolo11n.pt":
                model_path = Config.YOLO_MODEL_PATH
            elif yolo_model_select == "æœ¬åœ°æ¨¡å‹":
                # ä½¿ç”¨å…¨å±€å˜é‡ä¸­çš„æ¨¡å‹è·¯å¾„
                model_path = current_yolo_model_path
                # å¦‚æœå½“å‰æ²¡æœ‰æœ¬åœ°æ¨¡å‹ï¼Œå°è¯•ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­è·å–
                if model_path is None and local_model_file is not None:
                    if hasattr(local_model_file, 'name'):
                        model_path = local_model_file.name
                    else:
                        model_path = str(local_model_file)
            else:
                # ç›´æ¥ä½¿ç”¨ä¼ é€’çš„è·¯å¾„
                model_path = yolo_model_select

            # å¦‚æœæ¨¡å‹è·¯å¾„ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
            if model_path is None:
                model_path = Config.YOLO_MODEL_PATH
                print(f"âš ï¸ ä½¿ç”¨é»˜è®¤æ¨¡å‹: {model_path}")

            print(f"å›¾åƒä»»åŠ¡: å­ç±»å‹={cleaned_task_subtype}, æ¨¡å‹={model_path}, é˜ˆå€¼={conf_threshold}")

            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(model_path):
                yield f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {os.path.basename(model_path) if model_path else 'æœªçŸ¥'}", None, None, None, None, gr.update(
                    visible=False)
                return

            # è·å–YOLOæ£€æµ‹å™¨
            detector = get_yolo_detector(model_path, cleaned_task_subtype)
            if detector is None:
                yield "âŒ YOLOæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶", None, None, None, None, gr.update(visible=False)
                return

            total_files = len(all_file_infos)

            for i, file_info in enumerate(all_file_infos):
                file_path = file_info['name']
                filename = os.path.basename(file_path)
                file_paths.append(file_path)

                status_msg = f"æ­£åœ¨æ ‡æ³¨å›¾ç‰‡ {i + 1}/{total_files}: {filename}"
                yield status_msg, None, None, None, None, gr.update(visible=False)

                # æ‰§è¡Œä¸åŒç±»å‹çš„å›¾åƒä»»åŠ¡
                if cleaned_task_subtype == "ç›®æ ‡æ£€æµ‹":
                    detections = detector.detect(file_path, conf_threshold=conf_threshold)
                elif cleaned_task_subtype == "å›¾åƒåˆ†ç±»":
                    detections = detector.classify(file_path, conf_threshold=conf_threshold)
                elif cleaned_task_subtype == "å®ä¾‹åˆ†å‰²":
                    detections = detector.segment(file_path, conf_threshold=conf_threshold)
                else:
                    detections = []

                # ä¿å­˜åŸå§‹å›¾åƒå’Œæ£€æµ‹ç»“æœ
                original_image = Image.open(file_path)
                current_original_images[filename] = original_image
                current_detections[filename] = detections

                # ç”Ÿæˆå¯è§†åŒ–å›¾ç‰‡
                vis_path = os.path.join(Config.VISUALIZATION_DIR, f"vis_{filename}")
                vis_img = detector.visualize(file_path, detections, vis_path)

                # ä¿å­˜æ ‡æ³¨ç»“æœ
                if detections:
                    # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©ä¿å­˜æ ¼å¼
                    if cleaned_task_subtype == "ç›®æ ‡æ£€æµ‹":
                        # YOLOæ ¼å¼ä¿å­˜
                        yolo_txt_path = os.path.join(
                            Config.ANNOTATION_DIR,
                            f"{Path(filename).stem}.txt"
                        )
                        detector.save_yolo_format(filename, detections, yolo_txt_path)

                        # COCOæ ¼å¼ä¿å­˜
                        coco_json_path = os.path.join(
                            Config.ANNOTATION_DIR,
                            f"{Path(filename).stem}_coco.json"
                        )
                        detector.save_coco_format(filename, detections, coco_json_path)
                    elif cleaned_task_subtype == "å›¾åƒåˆ†ç±»":
                        # åˆ†ç±»ç»“æœä¿å­˜ä¸ºJSON
                        class_json_path = os.path.join(
                            Config.ANNOTATION_DIR,
                            f"{Path(filename).stem}_classification.json"
                        )
                        detector.save_classification_format(filename, detections, class_json_path)
                    elif cleaned_task_subtype == "å®ä¾‹åˆ†å‰²":
                        # åˆ†å‰²ç»“æœä¿å­˜
                        seg_json_path = os.path.join(
                            Config.ANNOTATION_DIR,
                            f"{Path(filename).stem}_segmentation.json"
                        )
                        detector.save_segmentation_format(filename, detections, seg_json_path)

                    # ä¸ºæ¯ä¸ªæ£€æµ‹ç»“æœåˆ›å»ºè®°å½•
                    for j, det in enumerate(detections):
                        if cleaned_task_subtype == "ç›®æ ‡æ£€æµ‹":
                            result = {
                                "id": f"{len(results) + 1:04d}",
                                "task_type": "å›¾åƒä»»åŠ¡-ç›®æ ‡æ£€æµ‹",
                                "image_file": filename,
                                "class_id": det.get('class_id', 0),
                                "class_name": det.get('class_name', 'unknown'),
                                "confidence": f"{det.get('confidence', 0):.4f}",
                                "bbox_xyxy": f"{det.get('bbox', [0, 0, 0, 0])[0]:.0f},{det.get('bbox', [0, 0, 0, 0])[1]:.0f},{det.get('bbox', [0, 0, 0, 0])[2]:.0f},{det.get('bbox', [0, 0, 0, 0])[3]:.0f}",
                                "bbox_yolo": f"{det.get('yolo_bbox', [0, 0, 0, 0])[0]:.6f},{det.get('yolo_bbox', [0, 0, 0, 0])[1]:.6f},{det.get('yolo_bbox', [0, 0, 0, 0])[2]:.6f},{det.get('yolo_bbox', [0, 0, 0, 0])[3]:.6f}",
                                "annotation_file": f"{Path(filename).stem}.txt",
                                "visualization": f"vis_{filename}"
                            }
                        elif cleaned_task_subtype == "å›¾åƒåˆ†ç±»":
                            result = {
                                "id": f"{len(results) + 1:04d}",
                                "task_type": "å›¾åƒä»»åŠ¡-å›¾åƒåˆ†ç±»",
                                "image_file": filename,
                                "class_id": det.get('class_id', 0),
                                "class_name": det.get('class_name', 'unknown'),
                                "confidence": f"{det.get('confidence', 0):.4f}",
                                "top_n": det.get('top_n', 5),
                                "annotation_file": f"{Path(filename).stem}_classification.json",
                                "visualization": f"vis_{filename}"
                            }
                        elif cleaned_task_subtype == "å®ä¾‹åˆ†å‰²":
                            result = {
                                "id": f"{len(results) + 1:04d}",
                                "task_type": "å›¾åƒä»»åŠ¡-å®ä¾‹åˆ†å‰²",
                                "image_file": filename,
                                "class_id": det.get('class_id', 0),
                                "class_name": det.get('class_name', 'unknown'),
                                "confidence": f"{det.get('confidence', 0):.4f}",
                                "bbox_xyxy": f"{det.get('bbox', [0, 0, 0, 0])[0]:.0f},{det.get('bbox', [0, 0, 0, 0])[1]:.0f},{det.get('bbox', [0, 0, 0, 0])[2]:.0f},{det.get('bbox', [0, 0, 0, 0])[3]:.0f}",
                                "mask_points": len(det.get('mask', [])) if det.get('mask') else 0,
                                "annotation_file": f"{Path(filename).stem}_segmentation.json",
                                "visualization": f"vis_{filename}"
                            }
                        results.append(result)

                    # æ·»åŠ å¯è§†åŒ–å›¾ç‰‡åˆ°è¿”å›åˆ—è¡¨
                    if vis_img is not None:
                        # è½¬æ¢BGRåˆ°RGB
                        vis_img_rgb = cv2.cvtColor(vis_img, cv2.COLOR_BGR2RGB)
                        # è½¬æ¢ä¸ºPILå›¾åƒ
                        pil_img = Image.fromarray(vis_img_rgb)
                        # æ·»åŠ æ ‡é¢˜
                        caption = f"{filename} ({cleaned_task_subtype}: {len(detections)}ä¸ªç»“æœ)"
                        visualizations.append((pil_img, caption))

                yield f"å·²æ ‡æ³¨ {i + 1}/{total_files} å¼ å›¾ç‰‡ï¼Œæ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡", None, visualizations, 0, total_files, gr.update(
                    visible=True)
                time.sleep(0.5)

            # ä¿å­˜æ±‡æ€»ç»“æœ
            if results:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                summary_path = os.path.join(Config.OUTPUT_DIR, f"annotation_summary_{timestamp}.json")

                summary = {
                    "task_type": cleaned_task_subtype,
                    "total_images": total_files,
                    "total_detections": len(results),
                    "model_used": model_path,
                    "conf_threshold": conf_threshold,
                    "detections_by_class": {},
                    "annotations": results
                }

                # æŒ‰ç±»åˆ«ç»Ÿè®¡
                for result in results:
                    class_name = result['class_name']
                    summary["detections_by_class"][class_name] = \
                        summary["detections_by_class"].get(class_name, 0) + 1

                with open(summary_path, "w", encoding="utf-8") as f:
                    json.dump(summary, f, ensure_ascii=False, indent=2)

                df_results = pd.DataFrame(results)
                final_msg = f"âœ… å®Œæˆï¼{cleaned_task_subtype} - å·²æ ‡æ³¨ {total_files} å¼ å›¾ç‰‡ï¼Œæ£€æµ‹åˆ° {len(results)} ä¸ªç»“æœ\næ¨¡å‹: {os.path.basename(model_path) if model_path else 'é»˜è®¤'}\nå·²ä¿å­˜åˆ°: {summary_path}"
                current_results = results
                current_file_paths = file_paths
                current_visualizations = visualizations
                yield final_msg, df_results, visualizations, 0, total_files, gr.update(visible=True)
            else:
                yield f"âŒ æœªèƒ½æ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡ (ä»»åŠ¡: {cleaned_task_subtype})", None, None, None, None, gr.update(
                    visible=False)

        else:  # å¤šæ¨¡æ€ç”Ÿæˆ
            # ... [åŸæœ‰çš„å¤šæ¨¡æ€ç”Ÿæˆä»£ç ä¿æŒä¸å˜] ...
            if not api_key.strip():
                yield "è¯·è¾“å…¥APIå¯†é’¥", None, None, None, None, gr.update(visible=False)
                return

            handler = APIHandler(model_type, api_key.strip())
            total_files = len(all_file_infos)

            for i, file_info in enumerate(all_file_infos):
                file_path = file_info['name']
                filename = os.path.basename(file_path)
                file_paths.append(file_path)

                status_msg = f"æ­£åœ¨åˆ†æå›¾ç‰‡ {i + 1}/{total_files}: {filename}"
                yield status_msg, None, None, None, None, gr.update(visible=False)

                analysis = handler.analyze_image(file_path)

                result = {
                    "id": f"{len(results) + 1:04d}",
                    "task_type": "å›¾ç‰‡ç†è§£",
                    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªå·¥ä¸šå›¾ç‰‡åˆ†æä¸“å®¶",
                    "instruction": analysis.get("instruction", "è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"),
                    "image_file": filename,
                    "output": analysis.get("output", "åˆ†æå¤±è´¥")
                }
                results.append(result)

                progress = ((i + 1) / total_files) * 100
                yield f"å·²åˆ†æ {i + 1}/{total_files} å¼ å›¾ç‰‡ï¼Œè¿›åº¦: {progress:.1f}%", None, None, None, None, gr.update(
                    visible=False)
                time.sleep(0.5)

            if results:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                output_path = os.path.join(Config.OUTPUT_DIR, f"image_results_{timestamp}.json")

                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)

                final_msg = f"âœ… å®Œæˆï¼å·²åˆ†æ {len(results)} å¼ å›¾ç‰‡\nå·²ä¿å­˜åˆ°: {output_path}"
                df_results = pd.DataFrame(results)
                current_results = results
                current_file_paths = file_paths
                yield final_msg, df_results, None, None, None, gr.update(visible=True)
            else:
                yield "âŒ æœªèƒ½åˆ†æå›¾ç‰‡ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æˆ–APIé…ç½®", None, None, None, None, gr.update(visible=False)

    except Exception as e:
        error_msg = f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        yield error_msg, None, None, None, None, gr.update(visible=False)


def save_edited_results(results_df, task_type):
    """ä¿å­˜ç¼–è¾‘åçš„ç»“æœ"""
    global current_results

    try:
        if results_df is None or len(results_df) == 0:
            return "âŒ æ²¡æœ‰å¯ä¿å­˜çš„æ•°æ®", None

        # è½¬æ¢DataFrameä¸ºå­—å…¸åˆ—è¡¨
        edited_results = results_df.to_dict('records')

        # ä¿å­˜ç¼–è¾‘åçš„ç»“æœ
        timestamp = time.strftime("%Y%m%d_%H%M%S")

        if task_type == "é—®ç­”å¯¹ç”Ÿæˆ":
            output_path = os.path.join(Config.OUTPUT_DIR, f"edited_qa_results_{timestamp}.json")
        elif task_type == "å›¾åƒä»»åŠ¡":
            output_path = os.path.join(Config.OUTPUT_DIR, f"edited_annotation_results_{timestamp}.json")
        else:  # å¤šæ¨¡æ€ç”Ÿæˆ
            output_path = os.path.join(Config.OUTPUT_DIR, f"edited_image_results_{timestamp}.json")

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(edited_results, f, ensure_ascii=False, indent=2)

        # æ›´æ–°å½“å‰ç»“æœ
        current_results = edited_results

        return f"âœ… ç¼–è¾‘åçš„ç»“æœå·²ä¿å­˜åˆ°: {output_path}", output_path
    except Exception as e:
        return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}", None


def navigate_images(direction, current_index, total_images):
    """å¯¼èˆªå›¾ç‰‡"""
    global current_editing_mode, current_edit_image_index

    if total_images == 0:
        return 0, None, None, None, None, gr.update(visible=False), gr.update(visible=False)

    new_index = current_index + direction

    if new_index < 0:
        new_index = total_images - 1
    elif new_index >= total_images:
        new_index = 0

    # é€€å‡ºç¼–è¾‘æ¨¡å¼
    if current_editing_mode:
        current_editing_mode = False
        current_edit_image_index = -1

    # è·å–å½“å‰å›¾ç‰‡
    if current_visualizations and len(current_visualizations) > new_index:
        vis_data = current_visualizations[new_index]
        if isinstance(vis_data, tuple):
            current_image, caption = vis_data

            # è·å–å½“å‰å›¾ç‰‡çš„æ–‡ä»¶å
            if current_file_paths and len(current_file_paths) > new_index:
                current_file = current_file_paths[new_index]
                filename = os.path.basename(current_file)

                # è·å–å½“å‰å›¾ç‰‡çš„æ£€æµ‹ç»“æœ
                image_results = [r for r in current_results if r.get('image_file') == filename]
                df_image_results = pd.DataFrame(image_results) if image_results else pd.DataFrame()

                return new_index, [(current_image,
                                    caption)], f"å›¾ç‰‡ {new_index + 1}/{total_images}: {filename}", df_image_results, gr.update(
                    visible=True), gr.update(visible=False)

    return new_index, None, f"å›¾ç‰‡ {new_index + 1}/{total_images}", None, gr.update(visible=False), gr.update(
        visible=False)


def toggle_edit_mode(current_index, total_images):
    """åˆ‡æ¢ç¼–è¾‘æ¨¡å¼"""
    global current_editing_mode, current_edit_image_index, current_edit_annotations

    if total_images == 0 or current_index < 0:
        return gr.update(visible=False), "âŒ æ²¡æœ‰å›¾ç‰‡å¯ç¼–è¾‘"

    current_editing_mode = not current_editing_mode

    if current_editing_mode:
        current_edit_image_index = current_index

        # è·å–å½“å‰å›¾ç‰‡
        if current_file_paths and len(current_file_paths) > current_index:
            current_file = current_file_paths[current_index]
            filename = os.path.basename(current_file)

            # è·å–å½“å‰å›¾ç‰‡çš„æ£€æµ‹ç»“æœ
            image_results = [r for r in current_results if r.get('image_file') == filename]
            current_edit_annotations = image_results.copy()

            return gr.update(visible=True), f"ğŸ“ è¿›å…¥ç¼–è¾‘æ¨¡å¼: {filename}\nåŒå‡»åæ ‡è¿›è¡Œä¿®æ”¹ï¼ŒæŒ‰Enterä¿å­˜"
    else:
        return gr.update(visible=False), "é€€å‡ºç¼–è¾‘æ¨¡å¼"


def update_annotation(image_index, annotations_df):
    """æ ¹æ®ç¼–è¾‘çš„è¡¨æ ¼æ›´æ–°æ ‡æ³¨"""
    global current_results, current_visualizations

    if image_index < 0 or not current_file_paths or len(current_file_paths) <= image_index:
        return None, None, "âŒ æ›´æ–°å¤±è´¥: æ— æ•ˆçš„å›¾ç‰‡ç´¢å¼•"

    try:
        file_path = current_file_paths[image_index]
        filename = os.path.basename(file_path)

        # åŠ è½½åŸå§‹å›¾åƒ
        original_image = Image.open(file_path)
        draw = ImageDraw.Draw(original_image)

        # æ›´æ–°å½“å‰ç»“æœ
        updated_results = []

        # ä¿ç•™ä¸æ˜¯å½“å‰å›¾ç‰‡çš„å…¶ä»–ç»“æœ
        for result in current_results:
            if result.get('image_file') != filename:
                updated_results.append(result)

        # å¤„ç†ç¼–è¾‘åçš„ç»“æœ
        if annotations_df is not None and len(annotations_df) > 0:
            for _, row in annotations_df.iterrows():
                try:
                    # åˆ›å»ºæ–°ç»“æœ
                    new_result = {
                        "id": str(row.get('ID', f"{len(updated_results) + 1:04d}")),
                        "task_type": "å›¾åƒä»»åŠ¡",
                        "image_file": filename,
                        "class_id": get_class_id(str(row.get('ç±»åˆ«', ''))),
                        "class_name": str(row.get('ç±»åˆ«', '')),
                        "confidence": str(row.get('ç½®ä¿¡åº¦', '0.80')),
                        "bbox_xyxy": str(row.get('åæ ‡(x1,y1,x2,y2)', '0,0,100,100')),
                        "bbox_yolo": convert_xyxy_to_yolo(
                            list(map(float, str(row.get('åæ ‡(x1,y1,x2,y2)', '0,0,100,100')).split(','))),
                            original_image.width,
                            original_image.height
                        ),
                        "annotation_file": f"{Path(filename).stem}_edited.txt",
                        "visualization": f"vis_{filename}",
                        "is_edited": True
                    }
                    updated_results.append(new_result)

                    # ç»˜åˆ¶æ¡†
                    bbox_str = str(row.get('åæ ‡(x1,y1,x2,y2)', '0,0,100,100'))
                    if bbox_str:
                        bbox = list(map(int, map(float, bbox_str.split(','))))
                        draw.rectangle(bbox, outline='red', width=3)
                        label = f"{row.get('ç±»åˆ«', '')} {row.get('ç½®ä¿¡åº¦', '')}"
                        draw.text((bbox[0], bbox[1] - 15), label, fill='red')
                except Exception as e:
                    print(f"å¤„ç†è¡Œæ—¶å‡ºé”™: {e}")
                    continue

        # æ›´æ–°å…¨å±€å˜é‡
        current_results = updated_results

        # æ›´æ–°å¯è§†åŒ–å›¾åƒ
        caption = f"{filename} (å·²ç¼–è¾‘ï¼Œ{len([r for r in updated_results if r.get('image_file') == filename])}ä¸ªç›®æ ‡)"
        if current_visualizations and len(current_visualizations) > image_index:
            current_visualizations[image_index] = (original_image, caption)

        # æ›´æ–°æ•°æ®æ¡†
        image_results = [r for r in updated_results if r.get('image_file') == filename]
        df_image_results = pd.DataFrame(image_results) if image_results else pd.DataFrame()

        return [(original_image, caption)], df_image_results, f"âœ… æ ‡æ³¨å·²æ›´æ–°: {filename}"

    except Exception as e:
        return None, None, f"âŒ æ›´æ–°å¤±è´¥: {str(e)}"


def add_new_annotation(image_index, class_name, confidence):
    """æ·»åŠ æ–°çš„æ ‡æ³¨"""
    global current_edit_annotations

    if image_index < 0 or not current_file_paths or len(current_file_paths) <= image_index:
        return gr.update(), "âŒ æ·»åŠ å¤±è´¥: æ— æ•ˆçš„å›¾ç‰‡ç´¢å¼•"

    try:
        # åˆ›å»ºæ–°çš„æ ‡æ³¨
        new_annotation = {
            "id": f"{len(current_edit_annotations) + 1:04d}",
            "å›¾åƒæ–‡ä»¶": os.path.basename(current_file_paths[image_index]),
            "ç±»åˆ«": class_name,
            "ç½®ä¿¡åº¦": f"{confidence:.2f}",
            "åæ ‡(x1,y1,x2,y2)": "0,0,100,100"  # é»˜è®¤åæ ‡ï¼Œç”¨æˆ·å¯ä»¥åœ¨è¡¨æ ¼ä¸­ä¿®æ”¹
        }

        # æ·»åŠ åˆ°å½“å‰ç¼–è¾‘çš„æ ‡æ³¨åˆ—è¡¨
        current_edit_annotations.append(new_annotation)

        # æ›´æ–°è¡¨æ ¼
        df_annotations = pd.DataFrame(current_edit_annotations)

        return df_annotations, f"âœ… å·²æ·»åŠ æ–°æ ‡æ³¨: {class_name}"

    except Exception as e:
        return gr.update(), f"âŒ æ·»åŠ å¤±è´¥: {str(e)}"


def get_class_id(class_name):
    """æ ¹æ®ç±»åˆ«åç§°è·å–ç±»åˆ«ID"""
    # ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”è¯¥ä»YOLOæ¨¡å‹ä¸­è·å–
    class_mapping = {
        "person": 0, "cat": 15, "dog": 16, "car": 2, "bicycle": 1,
        "motorcycle": 3, "bus": 5, "truck": 7, "bird": 14, "horse": 17
    }
    return class_mapping.get(class_name.lower(), 0)


def convert_xyxy_to_yolo(bbox_xyxy, img_width, img_height):
    """å°†XYXYåæ ‡è½¬æ¢ä¸ºYOLOæ ¼å¼"""
    x1, y1, x2, y2 = bbox_xyxy

    # è®¡ç®—ä¸­å¿ƒç‚¹åæ ‡
    x_center = (x1 + x2) / 2 / img_width
    y_center = (y1 + y2) / 2 / img_height

    # è®¡ç®—å®½åº¦å’Œé«˜åº¦
    width = (x2 - x1) / img_width
    height = (y2 - y1) / img_height

    return f"{x_center:.6f},{y_center:.6f},{width:.6f},{height:.6f}"


def save_current_annotations():
    """ä¿å­˜å½“å‰æ ‡æ³¨ç»“æœ"""
    global current_results

    try:
        if not current_results:
            return "âŒ æ²¡æœ‰å¯ä¿å­˜çš„æ ‡æ³¨æ•°æ®", None

        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(Config.OUTPUT_DIR, f"interactive_annotations_{timestamp}.json")

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(current_results, f, ensure_ascii=False, indent=2)

        return f"âœ… äº¤äº’å¼æ ‡æ³¨ç»“æœå·²ä¿å­˜åˆ°: {output_path}", output_path
    except Exception as e:
        return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}", None


def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    css = """
    .gradio-container {
        background: url('https://images.unsplash.com/photo-1451187580459-43490279c0fa?ixlib=rb-4.0.3&auto=format&fit=crop&w=2072&q=80') center/cover no-repeat fixed !important;
        min-height: 100vh !important;
        padding: 20px !important;
        font-family: 'Microsoft YaHei', 'Segoe UI', sans-serif;
    }
    .gradio-container::before {
        content: '';
        position: fixed;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: rgba(0, 0, 0, 0.6);
        z-index: -1;
    }
    .gradio-container > * {
        position: relative;
        z-index: 1;
    }
    .main-header {
        text-align: center;
        font-size: 48px !important;
        font-weight: bold !important;
        color: white !important;
        margin-bottom: 20px !important;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        padding: 25px;
        background: linear-gradient(135deg, rgba(102, 126, 234, 0.9) 0%, rgba(118, 75, 162, 0.9) 100%);
        border-radius: 20px;
        border: 3px solid rgba(255, 255, 255, 0.2);
    }
    .app-subtitle {
        text-align: center;
        font-size: 20px !important;
        color: #e0e0e0 !important;
        margin-bottom: 40px !important;
        line-height: 1.6;
        padding: 0 20px;
    }
    .gr-box {
        background: rgba(255, 255, 255, 0.95) !important;
        border-radius: 15px !important;
        padding: 25px !important;
        margin-bottom: 20px !important;
        border: 1px solid rgba(255, 255, 255, 0.2) !important;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1) !important;
        backdrop-filter: blur(10px);
        /* ç¡®ä¿æ‰€æœ‰gr-boxå‚ç›´é¡¶éƒ¨å¯¹é½ */
        vertical-align: top !important;
    }
    .annotation-editor {
        background: rgba(255, 255, 255, 0.98) !important;
        border: 2px solid #667eea !important;
        border-radius: 15px !important;
        padding: 20px !important;
        margin-top: 20px !important;
    }
    .edit-controls {
        background: rgba(255, 255, 255, 0.98) !important;
        border: 2px solid #28a745 !important;
        border-radius: 15px !important;
        padding: 15px !important;
        margin-bottom: 15px !important;
    }
    .gr-button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        border: none !important;
        border-radius: 10px !important;
        padding: 12px 24px !important;
        font-weight: bold !important;
        transition: all 0.3s ease !important;
        margin: 5px !important;
    }
    .gr-button:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2) !important;
    }
    .gr-button-edit {
        background: linear-gradient(135deg, #28a745 0%, #218838 100%) !important;
    }
    .gr-button-cancel {
        background: linear-gradient(135deg, #dc3545 0%, #c82333 100%) !important;
    }
    .download-section {
        max-width: 600px !important;
        margin: 0 auto !important;
    }
    .right-column {
        margin-top: 0 !important;
    }
    .edit-table {
        max-height: 300px !important;
        overflow-y: auto !important;
        border: 1px solid #ddd !important;
        border-radius: 10px !important;
        padding: 10px !important;
    }
    .model-upload-group {
        background: rgba(255, 255, 255, 0.98) !important;
        border: 2px dashed #667eea !important;
        border-radius: 10px !important;
        padding: 20px !important;
        margin-top: 10px !important;
    }
    .task-subtype-buttons {
        display: flex !important;
        justify-content: space-between !important;
        margin-bottom: 15px !important;
    }
    .task-subtype-btn {
        flex: 1 !important;
        margin: 0 5px !important;
    }
    """

    with gr.Blocks(title="å±±æ²³æ™ºèƒ½æ•°æ®æ ‡æ³¨å·¥å…·") as app:
        # é¡µé¢æ ‡é¢˜
        gr.HTML("""
        <div class="main-header">
            ğŸ­ å±±æ²³æ™ºèƒ½æ•°æ®æ ‡æ³¨å·¥å…·
        </div>
        <div class="app-subtitle">
            æ”¯æŒé—®ç­”å¯¹ç”Ÿæˆã€å›¾åƒä»»åŠ¡ã€å¤šæ¨¡æ€åˆ†æ | å›¾åƒä»»åŠ¡æ”¯æŒç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†ç±»ã€å®ä¾‹åˆ†å‰²
        </div>
        """)

        # çŠ¶æ€å˜é‡
        task_type_state = gr.State("é—®ç­”å¯¹ç”Ÿæˆ")
        current_image_index = gr.State(0)
        total_images = gr.State(0)

        with gr.Row(equal_height=True):
            with gr.Column(scale=1):
                with gr.Group(elem_classes="gr-box"):
                    # å·¥ä½œæ¨¡å¼
                    task_type = gr.Radio(
                        choices=["é—®ç­”å¯¹ç”Ÿæˆ", "å›¾åƒä»»åŠ¡", "å¤šæ¨¡æ€ç”Ÿæˆ"],
                        label="ğŸ“‹ å·¥ä½œæ¨¡å¼",
                        value="é—®ç­”å¯¹ç”Ÿæˆ"
                    )

                    # æ¨¡å‹é€‰æ‹©
                    model_type = gr.Dropdown(
                        choices=list(API_CONFIG.keys()),
                        label="ğŸ¤– AIæ¨¡å‹",
                        value="DeepSeek",
                        visible=True
                    )

                    # å¤šæ¨¡æ€æ¨¡å‹
                    vision_model = gr.Textbox(
                        label="å¤šæ¨¡æ€æ¨¡å‹åç§°",
                        placeholder="ä¾‹å¦‚ï¼šgpt-4-vision-preview",
                        visible=False
                    )

                    # APIå¯†é’¥
                    api_key = gr.Textbox(
                        label="ğŸ”‘ APIå¯†é’¥",
                        placeholder="è¯·è¾“å…¥APIå¯†é’¥",
                        type="password",
                        visible=True
                    )

                    # æµ‹è¯•è¿æ¥
                    test_btn = gr.Button("ğŸ“¡ æµ‹è¯•è¿æ¥", variant="primary", visible=True)
                    test_output = gr.Textbox(label="è¿æ¥çŠ¶æ€", interactive=False, visible=True)

                    # YOLOæ¨¡å‹é…ç½®
                    with gr.Group(visible=False) as yolo_config_group:
                        gr.Markdown("**å›¾åƒä»»åŠ¡é…ç½®**")

                        # ä»»åŠ¡å­ç±»å‹é€‰æ‹©
                        task_subtype = gr.Radio(
                            choices=["ğŸ¯ ç›®æ ‡æ£€æµ‹", "ğŸ–¼ï¸ å›¾åƒåˆ†ç±»", "ğŸ–Œï¸ å®ä¾‹åˆ†å‰²"],
                            label="ä»»åŠ¡ç±»å‹",
                            value="ğŸ¯ ç›®æ ‡æ£€æµ‹",
                            elem_classes="task-subtype-buttons"
                        )

                        # æ¨¡å‹é€‰æ‹©
                        yolo_model_select = gr.Radio(
                            choices=["yolo11n.pt", "æœ¬åœ°æ¨¡å‹"],
                            label="é€‰æ‹©æ¨¡å‹",
                            value="yolo11n.pt",
                            visible=True
                        )

                        # æœ¬åœ°æ¨¡å‹ä¸Šä¼ 
                        with gr.Group(visible=False) as local_model_upload_group:
                            local_model_file = gr.File(
                                label="ä¸Šä¼ æœ¬åœ°æ¨¡å‹æ–‡ä»¶",
                                file_types=[".pt"],
                                elem_classes="model-upload-group"
                            )
                            local_model_status = gr.Textbox(
                                label="æ¨¡å‹çŠ¶æ€",
                                interactive=False,
                                visible=True
                            )

                        # ç½®ä¿¡åº¦é˜ˆå€¼
                        conf_threshold = gr.Slider(
                            minimum=0.1,
                            maximum=0.9,
                            value=0.25,
                            step=0.05,
                            label="ç½®ä¿¡åº¦é˜ˆå€¼"
                        )

                        # æ¨¡å‹ä¿¡æ¯æ˜¾ç¤º
                        model_info = gr.Markdown("**æ¨¡å‹:** yolo11n.pt | **ä»»åŠ¡:** ç›®æ ‡æ£€æµ‹")

                    # é¢„è®¾åœºæ™¯
                    preset_type = gr.Dropdown(
                        choices=list(PRESETS.keys()) + ["è‡ªå®šä¹‰æç¤ºè¯"],
                        label="ğŸ“‹ é¢„è®¾åœºæ™¯",
                        value="èƒ½ç¢³çŸ¥è¯†æŸ¥è¯¢",
                        visible=True
                    )

                    # è‡ªå®šä¹‰æç¤ºè¯
                    with gr.Group(visible=True) as custom_prompt_group:
                        custom_system_prompt = gr.Textbox(
                            label="ç³»ç»Ÿæç¤ºè¯",
                            placeholder="ä¾‹å¦‚ï¼šä½ æ˜¯ä¸€ä¸ªèƒ½ç¢³é¢†åŸŸåˆ†æå¸ˆ...",
                            lines=2
                        )
                        custom_task_prompt = gr.Textbox(
                            label="ä»»åŠ¡æç¤ºè¯",
                            placeholder="ä¾‹å¦‚ï¼šè¯·ç”Ÿæˆç¢³æ ¸ç®—ç›¸å…³çš„é—®ç­”å¯¹...",
                            lines=2
                        )

                    # å¹¶å‘æ•°
                    concurrency = gr.Slider(
                        minimum=1,
                        maximum=10,
                        value=3,
                        step=1,
                        label="âš¡ å¹¶å‘è¯·æ±‚æ•°",
                        visible=True
                    )

            with gr.Column(scale=2, elem_classes="right-column"):
                # æ–‡æœ¬è¾“å…¥åŒºåŸŸ
                with gr.Group(visible=True) as text_input_group:
                    text_input = gr.Textbox(
                        label="ğŸ“ è¾“å…¥æ–‡æœ¬å†…å®¹ï¼ˆå¯é€‰ï¼‰",
                        placeholder="è¯·åœ¨è¿™é‡Œç²˜è´´æˆ–è¾“å…¥æ–‡æœ¬å†…å®¹...",
                        lines=8,
                        max_lines=20,
                        elem_id="text-input"
                    )

                # ç»Ÿä¸€æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
                with gr.Group(elem_classes="gr-box"):
                    gr.Markdown("### ğŸ“ ä¸Šä¼ æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹")
                    file_upload = gr.File(
                        label="æ‹–æ‹½æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹åˆ°æ­¤å¤„",
                        file_count="multiple",
                        file_types=[".pdf", ".jpg", ".jpeg", ".png", ".bmp", ".gif", "directory"],
                        elem_id="unified-upload"
                    )
                    gr.Markdown("*æ”¯æŒä¸Šä¼ å•ä¸ªæ–‡ä»¶ã€å¤šä¸ªæ–‡ä»¶æˆ–æ•´ä¸ªæ–‡ä»¶å¤¹*")

                # å¤„ç†æŒ‰é’®
                process_btn = gr.Button("ğŸš€ å¼€å§‹å¤„ç†", variant="primary", size="lg")

                # çŠ¶æ€æ˜¾ç¤º
                status_display = gr.Textbox(
                    label="ğŸ“Š å¤„ç†çŠ¶æ€",
                    lines=4,
                    interactive=False
                )

                # å›¾åƒä»»åŠ¡å¯è§†åŒ–åŒºåŸŸ
                with gr.Group(visible=False) as visualization_group:
                    gr.Markdown("### ğŸ–¼ï¸ æ£€æµ‹å¯è§†åŒ–ç»“æœ")

                    # ç¼–è¾‘æ§åˆ¶æŒ‰é’®
                    with gr.Row():
                        edit_toggle_btn = gr.Button("âœï¸ è¿›å…¥ç¼–è¾‘æ¨¡å¼", variant="primary", elem_classes="gr-button-edit",
                                                    visible=True)
                        edit_status = gr.Textbox(label="ç¼–è¾‘çŠ¶æ€", interactive=False, visible=False, lines=2)

                    # ç¼–è¾‘æ§åˆ¶é¢æ¿
                    with gr.Group(visible=False) as edit_control_group:
                        gr.Markdown("### ç¼–è¾‘æ§åˆ¶")
                        with gr.Row():
                            new_class_name = gr.Textbox(
                                label="æ–°å¢ç±»åˆ«åç§°",
                                placeholder="è¾“å…¥æ–°ç›®æ ‡çš„ç±»åˆ«åç§°",
                                value="person"
                            )
                            new_confidence = gr.Slider(
                                minimum=0.1,
                                maximum=1.0,
                                value=0.8,
                                step=0.1,
                                label="ç½®ä¿¡åº¦"
                            )
                            add_annotation_btn = gr.Button("â• æ·»åŠ æ–°æ ‡æ³¨", variant="secondary")

                        add_status = gr.Textbox(label="æ·»åŠ çŠ¶æ€", interactive=False, visible=False)

                    # å¯è§†åŒ–å±•ç¤º
                    visualization_gallery = gr.Gallery(
                        label="æ£€æµ‹ç»“æœé¢„è§ˆ",
                        columns=2,
                        show_label=True,
                        height=400
                    )

                    # å›¾ç‰‡å¯¼èˆªåŒºåŸŸ
                    with gr.Group(visible=True) as image_navigation_group:
                        gr.Markdown("### å›¾ç‰‡å¯¼èˆª")
                        with gr.Row():
                            prev_btn = gr.Button("â¬…ï¸ ä¸Šä¸€å¼ ", variant="secondary")
                            image_counter = gr.Textbox(
                                label="å½“å‰å›¾ç‰‡",
                                value="0/0",
                                interactive=False
                            )
                            next_btn = gr.Button("â¡ï¸ ä¸‹ä¸€å¼ ", variant="secondary")
                            update_btn = gr.Button("ğŸ”„ æ›´æ–°å›¾åƒ", variant="secondary", visible=False)

                    # å½“å‰å›¾ç‰‡æ ‡æ³¨è¯¦æƒ…
                    current_image_results = gr.DataFrame(
                        label="å½“å‰å›¾ç‰‡æ ‡æ³¨è¯¦æƒ…ï¼ˆå¯ç¼–è¾‘ï¼‰",
                        headers=["ID", "å›¾åƒæ–‡ä»¶", "ç±»åˆ«", "ç½®ä¿¡åº¦", "åæ ‡(x1,y1,x2,y2)"],
                        datatype=["str", "str", "str", "str", "str"],
                        interactive=True,
                        wrap=True,
                        visible=False
                    )

                # ç»“æœè¡¨æ ¼
                results_table = gr.DataFrame(
                    label="ğŸ“‹ ç”Ÿæˆç»“æœï¼ˆå¯ç¼–è¾‘ï¼‰",
                    headers=["ID", "ä»»åŠ¡ç±»å‹", "å›¾åƒ/æºæ–‡ä»¶", "ç±»åˆ«/é—®é¢˜", "ç½®ä¿¡åº¦/å›ç­”"],
                    datatype=["str", "str", "str", "str", "str"],
                    interactive=True,
                    wrap=True,
                    visible=True
                )

        # ä¸‹è½½åŒºåŸŸ
        with gr.Row():
            with gr.Column(scale=2):
                with gr.Group(elem_classes="gr-box download-section"):
                    gr.Markdown("### ç»“æœæ“ä½œ")
                    with gr.Row():
                        save_btn = gr.Button("ğŸ’¾ ä¿å­˜ç¼–è¾‘ç»“æœ", variant="success")
                        save_interactive_btn = gr.Button("ğŸ’¾ ä¿å­˜äº¤äº’å¼æ ‡æ³¨", variant="primary", visible=False)
                        download_btn = gr.Button("ğŸ“¥ ä¸‹è½½ç»“æœæ–‡ä»¶", variant="secondary")

                    save_status = gr.Textbox(
                        label="ä¿å­˜çŠ¶æ€",
                        interactive=False,
                        visible=False
                    )

        # äº‹ä»¶å¤„ç†
        # ä»»åŠ¡ç±»å‹å˜åŒ–
        task_type.change(
            update_ui_components,
            inputs=[task_type],
            outputs=[
                model_type, api_key, test_btn, test_output,
                yolo_config_group, preset_type, concurrency,
                visualization_group, image_navigation_group,
                task_type_state, vision_model, custom_prompt_group,
                text_input_group, edit_toggle_btn, edit_control_group
            ]
        ).then(
            update_file_upload,
            inputs=[task_type],
            outputs=[file_upload]
        ).then(
            lambda x: gr.update(visible=True if x == "å›¾åƒä»»åŠ¡" else False),
            inputs=[task_type],
            outputs=[save_interactive_btn]
        )

        # å›¾åƒä»»åŠ¡å­ç±»å‹å˜åŒ–
        task_subtype.change(
            update_image_task_ui,
            inputs=[task_subtype, yolo_model_select],
            outputs=[yolo_model_select, local_model_upload_group, model_info, local_model_status]
            # æ·»åŠ  local_model_status
        )

        # YOLOæ¨¡å‹é€‰æ‹©å˜åŒ–
        yolo_model_select.change(
            update_yolo_model_selection,
            inputs=[yolo_model_select],
            outputs=[yolo_model_select, local_model_upload_group, model_info]
        )

        # æœ¬åœ°æ¨¡å‹ä¸Šä¼ 
        local_model_file.change(
            handle_local_model_upload,
            inputs=[local_model_file],
            outputs=[local_model_file, local_model_status, yolo_model_select]
        ).then(
            # ä¸Šä¼ åæ›´æ–°ä»»åŠ¡UIï¼Œä½¿ç”¨å½“å‰çš„å­ä»»åŠ¡ç±»å‹
            update_image_task_ui,
            inputs=[task_subtype, yolo_model_select],
            outputs=[yolo_model_select, local_model_upload_group, model_info, local_model_status]
        )


        # æµ‹è¯•è¿æ¥
        test_btn.click(
            test_api_connection,
            inputs=[api_key, model_type],
            outputs=test_output
        )

        # å¤„ç†æ–‡ä»¶
        process_btn.click(
            process_files,
            inputs=[
                file_upload, task_type, model_type, api_key, preset_type,
                custom_system_prompt, custom_task_prompt, concurrency, text_input, vision_model,
                task_subtype, yolo_model_select, local_model_file, conf_threshold
            ],
            outputs=[status_display, results_table, visualization_gallery,
                     current_image_index, total_images, save_btn]
        )

        # å›¾ç‰‡å¯¼èˆª
        prev_btn.click(
            navigate_images,
            inputs=[gr.State(-1), current_image_index, total_images],
            outputs=[current_image_index, visualization_gallery, image_counter,
                     current_image_results, edit_control_group, update_btn]
        )

        next_btn.click(
            navigate_images,
            inputs=[gr.State(1), current_image_index, total_images],
            outputs=[current_image_index, visualization_gallery, image_counter,
                     current_image_results, edit_control_group, update_btn]
        )

        # åˆ‡æ¢ç¼–è¾‘æ¨¡å¼
        edit_toggle_btn.click(
            toggle_edit_mode,
            inputs=[current_image_index, total_images],
            outputs=[edit_control_group, edit_status]
        )

        # æ·»åŠ æ–°æ ‡æ³¨
        add_annotation_btn.click(
            add_new_annotation,
            inputs=[current_image_index, new_class_name, new_confidence],
            outputs=[current_image_results, add_status]
        )

        # æ›´æ–°å›¾åƒ
        update_btn.click(
            update_annotation,
            inputs=[current_image_index, current_image_results],
            outputs=[visualization_gallery, current_image_results, status_display]
        )

        # ä¿å­˜ç¼–è¾‘ç»“æœ
        save_btn.click(
            save_edited_results,
            inputs=[results_table, task_type_state],
            outputs=[save_status, download_btn]
        )

        # ä¿å­˜äº¤äº’å¼æ ‡æ³¨
        save_interactive_btn.click(
            save_current_annotations,
            outputs=[save_status, download_btn]
        )

        # ä¸‹è½½ç»“æœ
        download_btn.click(
            lambda x: x,
            inputs=[download_btn],
            outputs=gr.File(label="ä¸‹è½½æ–‡ä»¶")
        )

    return app, css


if __name__ == "__main__":
    # å¯åŠ¨åº”ç”¨
    app, css = create_interface()

    app.launch(
        server_name="0.0.0.0",
        server_port=7861,
        share=False,
        debug=True,
        show_error=True,
        theme=gr.themes.Soft(),
        css=css
    )